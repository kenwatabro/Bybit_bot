{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2024-02-13 00:00:00+09:19 to 2024-02-14 00:00:00+09:19\n",
      "Fetching data from 2024-02-14 00:00:00+09:19 to 2024-02-15 00:00:00+09:19\n",
      "Fetching data from 2024-02-15 00:00:00+09:19 to 2024-02-16 00:00:00+09:19\n",
      "Fetching data from 2024-02-16 00:00:00+09:19 to 2024-02-17 00:00:00+09:19\n",
      "Fetching data from 2024-02-17 00:00:00+09:19 to 2024-02-18 00:00:00+09:19\n",
      "Fetching data from 2024-02-18 00:00:00+09:19 to 2024-02-19 00:00:00+09:19\n",
      "Fetching data from 2024-02-19 00:00:00+09:19 to 2024-02-20 00:00:00+09:19\n",
      "Fetching data from 2024-02-20 00:00:00+09:19 to 2024-02-21 00:00:00+09:19\n",
      "Fetching data from 2024-02-21 00:00:00+09:19 to 2024-02-22 00:00:00+09:19\n",
      "Fetching data from 2024-02-22 00:00:00+09:19 to 2024-02-23 00:00:00+09:19\n",
      "Fetching data from 2024-02-23 00:00:00+09:19 to 2024-02-24 00:00:00+09:19\n",
      "Fetching data from 2024-02-24 00:00:00+09:19 to 2024-02-25 00:00:00+09:19\n",
      "Fetching data from 2024-02-25 00:00:00+09:19 to 2024-02-26 00:00:00+09:19\n",
      "Fetching data from 2024-02-26 00:00:00+09:19 to 2024-02-27 00:00:00+09:19\n",
      "Fetching data from 2024-02-27 00:00:00+09:19 to 2024-02-28 00:00:00+09:19\n",
      "Fetching data from 2024-02-28 00:00:00+09:19 to 2024-02-29 00:00:00+09:19\n",
      "Fetching data from 2024-02-29 00:00:00+09:19 to 2024-03-01 00:00:00+09:19\n",
      "Fetching data from 2024-03-01 00:00:00+09:19 to 2024-03-02 00:00:00+09:19\n",
      "Fetching data from 2024-03-02 00:00:00+09:19 to 2024-03-03 00:00:00+09:19\n",
      "Fetching data from 2024-03-03 00:00:00+09:19 to 2024-03-04 00:00:00+09:19\n",
      "Fetching data from 2024-03-04 00:00:00+09:19 to 2024-03-05 00:00:00+09:19\n",
      "Fetching data from 2024-03-05 00:00:00+09:19 to 2024-03-06 00:00:00+09:19\n",
      "Fetching data from 2024-03-06 00:00:00+09:19 to 2024-03-07 00:00:00+09:19\n",
      "Fetching data from 2024-03-07 00:00:00+09:19 to 2024-03-08 00:00:00+09:19\n",
      "Fetching data from 2024-03-08 00:00:00+09:19 to 2024-03-09 00:00:00+09:19\n",
      "Fetching data from 2024-03-09 00:00:00+09:19 to 2024-03-10 00:00:00+09:19\n",
      "Fetching data from 2024-03-10 00:00:00+09:19 to 2024-03-11 00:00:00+09:19\n",
      "Fetching data from 2024-03-11 00:00:00+09:19 to 2024-03-12 00:00:00+09:19\n",
      "Fetching data from 2024-03-12 00:00:00+09:19 to 2024-03-13 00:00:00+09:19\n",
      "Fetching data from 2024-03-13 00:00:00+09:19 to 2024-03-14 00:00:00+09:19\n",
      "Fetching data from 2024-03-14 00:00:00+09:19 to 2024-03-15 00:00:00+09:19\n",
      "Fetching data from 2024-03-15 00:00:00+09:19 to 2024-03-16 00:00:00+09:19\n",
      "Fetching data from 2024-03-16 00:00:00+09:19 to 2024-03-17 00:00:00+09:19\n",
      "Fetching data from 2024-03-17 00:00:00+09:19 to 2024-03-18 00:00:00+09:19\n",
      "Fetching data from 2024-03-18 00:00:00+09:19 to 2024-03-19 00:00:00+09:19\n",
      "Fetching data from 2024-03-19 00:00:00+09:19 to 2024-03-20 00:00:00+09:19\n",
      "Fetching data from 2024-03-20 00:00:00+09:19 to 2024-03-21 00:00:00+09:19\n",
      "Fetching data from 2024-03-21 00:00:00+09:19 to 2024-03-22 00:00:00+09:19\n",
      "Fetching data from 2024-03-22 00:00:00+09:19 to 2024-03-23 00:00:00+09:19\n",
      "Fetching data from 2024-03-23 00:00:00+09:19 to 2024-03-24 00:00:00+09:19\n",
      "Fetching data from 2024-03-24 00:00:00+09:19 to 2024-03-25 00:00:00+09:19\n",
      "Fetching data from 2024-03-25 00:00:00+09:19 to 2024-03-26 00:00:00+09:19\n",
      "Fetching data from 2024-03-26 00:00:00+09:19 to 2024-03-27 00:00:00+09:19\n",
      "Fetching data from 2024-03-27 00:00:00+09:19 to 2024-03-28 00:00:00+09:19\n",
      "Fetching data from 2024-03-28 00:00:00+09:19 to 2024-03-29 00:00:00+09:19\n",
      "Fetching data from 2024-03-29 00:00:00+09:19 to 2024-03-30 00:00:00+09:19\n",
      "Fetching data from 2024-03-30 00:00:00+09:19 to 2024-03-31 00:00:00+09:19\n",
      "Fetching data from 2024-03-31 00:00:00+09:19 to 2024-04-01 00:00:00+09:19\n",
      "Fetching data from 2024-04-01 00:00:00+09:19 to 2024-04-02 00:00:00+09:19\n",
      "Fetching data from 2024-04-02 00:00:00+09:19 to 2024-04-03 00:00:00+09:19\n",
      "Fetching data from 2024-04-03 00:00:00+09:19 to 2024-04-04 00:00:00+09:19\n",
      "Fetching data from 2024-04-04 00:00:00+09:19 to 2024-04-05 00:00:00+09:19\n",
      "Fetching data from 2024-04-05 00:00:00+09:19 to 2024-04-06 00:00:00+09:19\n",
      "Fetching data from 2024-04-06 00:00:00+09:19 to 2024-04-07 00:00:00+09:19\n",
      "Fetching data from 2024-04-07 00:00:00+09:19 to 2024-04-08 00:00:00+09:19\n",
      "Fetching data from 2024-04-08 00:00:00+09:19 to 2024-04-09 00:00:00+09:19\n",
      "Fetching data from 2024-04-09 00:00:00+09:19 to 2024-04-10 00:00:00+09:19\n",
      "Fetching data from 2024-04-10 00:00:00+09:19 to 2024-04-11 00:00:00+09:19\n",
      "Fetching data from 2024-04-11 00:00:00+09:19 to 2024-04-12 00:00:00+09:19\n",
      "Fetching data from 2024-04-12 00:00:00+09:19 to 2024-04-13 00:00:00+09:19\n",
      "Fetching data from 2024-04-13 00:00:00+09:19 to 2024-04-14 00:00:00+09:19\n",
      "Fetching data from 2024-04-14 00:00:00+09:19 to 2024-04-15 00:00:00+09:19\n",
      "Fetching data from 2024-04-15 00:00:00+09:19 to 2024-04-16 00:00:00+09:19\n",
      "Fetching data from 2024-04-16 00:00:00+09:19 to 2024-04-17 00:00:00+09:19\n",
      "Fetching data from 2024-04-17 00:00:00+09:19 to 2024-04-18 00:00:00+09:19\n",
      "Fetching data from 2024-04-18 00:00:00+09:19 to 2024-04-19 00:00:00+09:19\n",
      "Fetching data from 2024-04-19 00:00:00+09:19 to 2024-04-20 00:00:00+09:19\n",
      "Fetching data from 2024-04-20 00:00:00+09:19 to 2024-04-21 00:00:00+09:19\n",
      "Fetching data from 2024-04-21 00:00:00+09:19 to 2024-04-22 00:00:00+09:19\n",
      "Fetching data from 2024-04-22 00:00:00+09:19 to 2024-04-23 00:00:00+09:19\n",
      "Fetching data from 2024-04-23 00:00:00+09:19 to 2024-04-24 00:00:00+09:19\n",
      "Fetching data from 2024-04-24 00:00:00+09:19 to 2024-04-25 00:00:00+09:19\n",
      "Fetching data from 2024-04-25 00:00:00+09:19 to 2024-04-26 00:00:00+09:19\n",
      "Fetching data from 2024-04-26 00:00:00+09:19 to 2024-04-27 00:00:00+09:19\n",
      "Fetching data from 2024-04-27 00:00:00+09:19 to 2024-04-28 00:00:00+09:19\n",
      "Fetching data from 2024-04-28 00:00:00+09:19 to 2024-04-29 00:00:00+09:19\n",
      "Fetching data from 2024-04-29 00:00:00+09:19 to 2024-04-30 00:00:00+09:19\n",
      "Fetching data from 2024-04-30 00:00:00+09:19 to 2024-05-01 00:00:00+09:19\n",
      "Fetching data from 2024-05-01 00:00:00+09:19 to 2024-05-02 00:00:00+09:19\n",
      "Fetching data from 2024-05-02 00:00:00+09:19 to 2024-05-03 00:00:00+09:19\n",
      "Fetching data from 2024-05-03 00:00:00+09:19 to 2024-05-04 00:00:00+09:19\n",
      "Fetching data from 2024-05-04 00:00:00+09:19 to 2024-05-05 00:00:00+09:19\n",
      "Fetching data from 2024-05-05 00:00:00+09:19 to 2024-05-06 00:00:00+09:19\n",
      "Fetching data from 2024-05-06 00:00:00+09:19 to 2024-05-07 00:00:00+09:19\n",
      "Fetching data from 2024-05-07 00:00:00+09:19 to 2024-05-08 00:00:00+09:19\n",
      "Fetching data from 2024-05-08 00:00:00+09:19 to 2024-05-09 00:00:00+09:19\n",
      "Fetching data from 2024-05-09 00:00:00+09:19 to 2024-05-10 00:00:00+09:19\n",
      "Fetching data from 2024-05-10 00:00:00+09:19 to 2024-05-11 00:00:00+09:19\n",
      "Fetching data from 2024-05-11 00:00:00+09:19 to 2024-05-12 00:00:00+09:19\n",
      "Fetching data from 2024-05-12 00:00:00+09:19 to 2024-05-13 00:00:00+09:19\n",
      "Fetching data from 2024-05-13 00:00:00+09:19 to 2024-05-14 00:00:00+09:19\n",
      "Fetching data from 2024-05-14 00:00:00+09:19 to 2024-05-15 00:00:00+09:19\n",
      "Fetching data from 2024-05-15 00:00:00+09:19 to 2024-05-16 00:00:00+09:19\n",
      "Fetching data from 2024-05-16 00:00:00+09:19 to 2024-05-17 00:00:00+09:19\n",
      "Fetching data from 2024-05-17 00:00:00+09:19 to 2024-05-18 00:00:00+09:19\n",
      "Fetching data from 2024-05-18 00:00:00+09:19 to 2024-05-19 00:00:00+09:19\n",
      "Fetching data from 2024-05-19 00:00:00+09:19 to 2024-05-20 00:00:00+09:19\n",
      "Fetching data from 2024-05-20 00:00:00+09:19 to 2024-05-21 00:00:00+09:19\n",
      "Fetching data from 2024-05-21 00:00:00+09:19 to 2024-05-22 00:00:00+09:19\n",
      "Fetching data from 2024-05-22 00:00:00+09:19 to 2024-05-23 00:00:00+09:19\n",
      "Fetching data from 2024-05-23 00:00:00+09:19 to 2024-05-24 00:00:00+09:19\n",
      "Fetching data from 2024-05-24 00:00:00+09:19 to 2024-05-25 00:00:00+09:19\n",
      "Fetching data from 2024-05-25 00:00:00+09:19 to 2024-05-26 00:00:00+09:19\n",
      "Fetching data from 2024-05-26 00:00:00+09:19 to 2024-05-27 00:00:00+09:19\n",
      "Fetching data from 2024-05-27 00:00:00+09:19 to 2024-05-28 00:00:00+09:19\n",
      "Fetching data from 2024-05-28 00:00:00+09:19 to 2024-05-29 00:00:00+09:19\n",
      "Fetching data from 2024-05-29 00:00:00+09:19 to 2024-05-30 00:00:00+09:19\n",
      "Fetching data from 2024-05-30 00:00:00+09:19 to 2024-05-31 00:00:00+09:19\n",
      "Fetching data from 2024-05-31 00:00:00+09:19 to 2024-06-01 00:00:00+09:19\n",
      "Fetching data from 2024-06-01 00:00:00+09:19 to 2024-06-02 00:00:00+09:19\n",
      "Fetching data from 2024-06-02 00:00:00+09:19 to 2024-06-03 00:00:00+09:19\n",
      "Fetching data from 2024-06-03 00:00:00+09:19 to 2024-06-04 00:00:00+09:19\n",
      "Fetching data from 2024-06-04 00:00:00+09:19 to 2024-06-05 00:00:00+09:19\n",
      "Fetching data from 2024-06-05 00:00:00+09:19 to 2024-06-06 00:00:00+09:19\n",
      "Fetching data from 2024-06-06 00:00:00+09:19 to 2024-06-07 00:00:00+09:19\n",
      "Fetching data from 2024-06-07 00:00:00+09:19 to 2024-06-08 00:00:00+09:19\n",
      "Fetching data from 2024-06-08 00:00:00+09:19 to 2024-06-09 00:00:00+09:19\n",
      "Fetching data from 2024-06-09 00:00:00+09:19 to 2024-06-10 00:00:00+09:19\n",
      "Fetching data from 2024-06-10 00:00:00+09:19 to 2024-06-11 00:00:00+09:19\n",
      "Fetching data from 2024-06-11 00:00:00+09:19 to 2024-06-12 00:00:00+09:19\n",
      "Fetching data from 2024-06-12 00:00:00+09:19 to 2024-06-13 00:00:00+09:19\n",
      "Fetching data from 2024-06-13 00:00:00+09:19 to 2024-06-14 00:00:00+09:19\n",
      "Fetching data from 2024-06-14 00:00:00+09:19 to 2024-06-15 00:00:00+09:19\n",
      "Fetching data from 2024-06-15 00:00:00+09:19 to 2024-06-16 00:00:00+09:19\n",
      "Fetching data from 2024-06-16 00:00:00+09:19 to 2024-06-17 00:00:00+09:19\n",
      "Fetching data from 2024-06-17 00:00:00+09:19 to 2024-06-18 00:00:00+09:19\n",
      "Fetching data from 2024-06-18 00:00:00+09:19 to 2024-06-19 00:00:00+09:19\n",
      "Fetching data from 2024-06-19 00:00:00+09:19 to 2024-06-20 00:00:00+09:19\n",
      "Fetching data from 2024-06-20 00:00:00+09:19 to 2024-06-21 00:00:00+09:19\n",
      "Fetching data from 2024-06-21 00:00:00+09:19 to 2024-06-22 00:00:00+09:19\n",
      "Fetching data from 2024-06-22 00:00:00+09:19 to 2024-06-23 00:00:00+09:19\n",
      "Fetching data from 2024-06-23 00:00:00+09:19 to 2024-06-24 00:00:00+09:19\n",
      "Fetching data from 2024-06-24 00:00:00+09:19 to 2024-06-25 00:00:00+09:19\n",
      "Fetching data from 2024-06-25 00:00:00+09:19 to 2024-06-26 00:00:00+09:19\n",
      "Fetching data from 2024-06-26 00:00:00+09:19 to 2024-06-27 00:00:00+09:19\n",
      "Fetching data from 2024-06-27 00:00:00+09:19 to 2024-06-28 00:00:00+09:19\n",
      "Fetching data from 2024-06-28 00:00:00+09:19 to 2024-06-29 00:00:00+09:19\n",
      "Fetching data from 2024-06-29 00:00:00+09:19 to 2024-06-30 00:00:00+09:19\n",
      "Fetching data from 2024-06-30 00:00:00+09:19 to 2024-07-01 00:00:00+09:19\n",
      "Fetching data from 2024-07-01 00:00:00+09:19 to 2024-07-02 00:00:00+09:19\n",
      "Fetching data from 2024-07-02 00:00:00+09:19 to 2024-07-03 00:00:00+09:19\n",
      "Fetching data from 2024-07-03 00:00:00+09:19 to 2024-07-04 00:00:00+09:19\n",
      "Fetching data from 2024-07-04 00:00:00+09:19 to 2024-07-05 00:00:00+09:19\n",
      "Fetching data from 2024-07-05 00:00:00+09:19 to 2024-07-06 00:00:00+09:19\n",
      "Fetching data from 2024-07-06 00:00:00+09:19 to 2024-07-07 00:00:00+09:19\n",
      "Fetching data from 2024-07-07 00:00:00+09:19 to 2024-07-08 00:00:00+09:19\n",
      "Fetching data from 2024-07-08 00:00:00+09:19 to 2024-07-09 00:00:00+09:19\n",
      "Fetching data from 2024-07-09 00:00:00+09:19 to 2024-07-10 00:00:00+09:19\n",
      "Fetching data from 2024-07-10 00:00:00+09:19 to 2024-07-11 00:00:00+09:19\n",
      "Fetching data from 2024-07-11 00:00:00+09:19 to 2024-07-12 00:00:00+09:19\n",
      "Fetching data from 2024-07-12 00:00:00+09:19 to 2024-07-13 00:00:00+09:19\n",
      "Fetching data from 2024-07-13 00:00:00+09:19 to 2024-07-14 00:00:00+09:19\n",
      "Fetching data from 2024-07-14 00:00:00+09:19 to 2024-07-15 00:00:00+09:19\n",
      "Fetching data from 2024-07-15 00:00:00+09:19 to 2024-07-16 00:00:00+09:19\n",
      "Fetching data from 2024-07-16 00:00:00+09:19 to 2024-07-17 00:00:00+09:19\n",
      "Fetching data from 2024-07-17 00:00:00+09:19 to 2024-07-18 00:00:00+09:19\n",
      "Fetching data from 2024-07-18 00:00:00+09:19 to 2024-07-19 00:00:00+09:19\n",
      "Fetching data from 2024-07-19 00:00:00+09:19 to 2024-07-20 00:00:00+09:19\n",
      "Fetching data from 2024-07-20 00:00:00+09:19 to 2024-07-21 00:00:00+09:19\n",
      "Fetching data from 2024-07-21 00:00:00+09:19 to 2024-07-22 00:00:00+09:19\n",
      "Fetching data from 2024-07-22 00:00:00+09:19 to 2024-07-23 00:00:00+09:19\n",
      "Fetching data from 2024-07-23 00:00:00+09:19 to 2024-07-24 00:00:00+09:19\n",
      "Fetching data from 2024-07-24 00:00:00+09:19 to 2024-07-25 00:00:00+09:19\n",
      "Fetching data from 2024-07-25 00:00:00+09:19 to 2024-07-26 00:00:00+09:19\n",
      "Fetching data from 2024-07-26 00:00:00+09:19 to 2024-07-27 00:00:00+09:19\n",
      "Fetching data from 2024-07-27 00:00:00+09:19 to 2024-07-28 00:00:00+09:19\n",
      "Fetching data from 2024-07-28 00:00:00+09:19 to 2024-07-29 00:00:00+09:19\n",
      "Fetching data from 2024-07-29 00:00:00+09:19 to 2024-07-30 00:00:00+09:19\n",
      "Fetching data from 2024-07-30 00:00:00+09:19 to 2024-07-31 00:00:00+09:19\n",
      "Fetching data from 2024-07-31 00:00:00+09:19 to 2024-08-01 00:00:00+09:19\n",
      "Fetching data from 2024-08-01 00:00:00+09:19 to 2024-08-02 00:00:00+09:19\n",
      "Fetching data from 2024-08-02 00:00:00+09:19 to 2024-08-03 00:00:00+09:19\n",
      "Fetching data from 2024-08-03 00:00:00+09:19 to 2024-08-04 00:00:00+09:19\n",
      "Fetching data from 2024-08-04 00:00:00+09:19 to 2024-08-05 00:00:00+09:19\n",
      "Fetching data from 2024-08-05 00:00:00+09:19 to 2024-08-06 00:00:00+09:19\n",
      "Fetching data from 2024-08-06 00:00:00+09:19 to 2024-08-07 00:00:00+09:19\n",
      "Fetching data from 2024-08-07 00:00:00+09:19 to 2024-08-08 00:00:00+09:19\n",
      "Fetching data from 2024-08-08 00:00:00+09:19 to 2024-08-09 00:00:00+09:19\n",
      "Fetching data from 2024-08-09 00:00:00+09:19 to 2024-08-10 00:00:00+09:19\n",
      "Fetching data from 2024-08-10 00:00:00+09:19 to 2024-08-11 00:00:00+09:19\n",
      "Total rows: 51840\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "BACKTEST_DATA_FOLDER = \"backtest_data\"\n",
    "\n",
    "\n",
    "def get_binance_klines(symbol, interval, start_time, end_time):\n",
    "    url = \"https://api.binance.com/api/v3/klines\"\n",
    "    params = {\n",
    "        \"symbol\": symbol,\n",
    "        \"interval\": interval,\n",
    "        \"startTime\": int(start_time.timestamp() * 1000),\n",
    "        \"endTime\": int(end_time.timestamp() * 1000),\n",
    "        \"limit\": 1000,\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=[\n",
    "            \"timestamp\",\n",
    "            \"open\",\n",
    "            \"high\",\n",
    "            \"low\",\n",
    "            \"close\",\n",
    "            \"volume\",\n",
    "            \"close_time\",\n",
    "            \"quote_asset_volume\",\n",
    "            \"number_of_trades\",\n",
    "            \"taker_buy_base_asset_volume\",\n",
    "            \"taker_buy_quote_asset_volume\",\n",
    "            \"ignore\",\n",
    "        ],\n",
    "    )\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\", utc=True)\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].dt.tz_convert(\"Asia/Tokyo\")  # UTCからJSTに変換\n",
    "    return df[[\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "\n",
    "def get_historical_data(symbol, interval, start_date, end_date):\n",
    "    all_data = []\n",
    "    current_date = start_date\n",
    "    while current_date < end_date:\n",
    "        next_date = min(current_date + timedelta(days=1), end_date)\n",
    "        print(f\"Fetching data from {current_date} to {next_date}\")\n",
    "        df = get_binance_klines(symbol, interval, current_date, next_date)\n",
    "        if df.empty:\n",
    "            print(f\"No data found for {symbol} in the specified time range.\")\n",
    "            exit()\n",
    "        all_data.append(df)\n",
    "        current_date = next_date\n",
    "        time.sleep(1)  # APIレート制限を考慮\n",
    "    return pd.concat(all_data)\n",
    "\n",
    "\n",
    "# パラメータ設定\n",
    "symbol = \"SOLUSDT\"\n",
    "interval = \"5m\"\n",
    "end_date = datetime(\n",
    "    2024, 8, 11, tzinfo=pytz.timezone(\"Asia/Tokyo\")\n",
    ")  # 固定の終了日（JST）\n",
    "start_date = end_date - timedelta(days=180)\n",
    "\n",
    "# データ取得\n",
    "historical_data = get_historical_data(symbol, interval, start_date, end_date)\n",
    "\n",
    "# CSVに保存\n",
    "historical_data.to_csv(\n",
    "    f\"{BACKTEST_DATA_FOLDER}/{symbol}_{interval}_{start_date.date()}_{end_date.date()}_JST.csv\", index=False\n",
    ")\n",
    "\n",
    "print(f\"Total rows: {len(historical_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv(\"backtest_data/SOLUSDT_5m_2024-02-13_2024-08-11_JST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data[\"timestamp\"] = pd.to_datetime(historical_data[\"timestamp\"])\n",
    "historical_data = historical_data[historical_data.timestamp.dt.date > pd.to_datetime(\"2024-07-21\").date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               open          high           low         close         volume\n",
      "count  51840.000000  51840.000000  51840.000000  51840.000000   51840.000000\n",
      "mean     152.750731    153.058877    152.434954    152.751953   17452.659700\n",
      "std       22.944563     22.978588     22.912077     22.943828   22053.676687\n",
      "min       98.570000     98.850000     98.480000     98.570000     379.726000\n",
      "25%      138.140000    138.470000    137.830000    138.140000    5977.100250\n",
      "50%      149.870000    150.200000    149.500000    149.870000   10547.949000\n",
      "75%      171.650000    171.950000    171.302500    171.650000   20292.988500\n",
      "max      209.740000    210.180000    208.970000    209.750000  796188.610000\n",
      "\n",
      "First 10 trades:\n",
      "[np.float64(0.017722640673460348), np.float64(-0.0015040254799610873), np.float64(0.013197619252997384), np.float64(0.0157679240351946), np.float64(0.015124712542013035), np.float64(0.02374977594551), np.float64(0.009431395665185511), np.float64(0.01770564367392108), np.float64(0.015902196893096698), np.float64(0.02205466540999061)]\n",
      "\n",
      "Last 10 trades:\n",
      "[np.float64(0.02901561348254381), np.float64(0.03034584847261466), np.float64(0.03529327713081373), np.float64(0.06195495563812836), np.float64(-0.0034768866060845335), np.float64(0.09959023694993757), np.float64(0.07787304334146154), np.float64(0.021251241310824093), np.float64(0.06902109172447617), np.float64(0.02134204960584511)]\n",
      "\n",
      "Backtesting Results:\n",
      "Total Return: 620.24%\n",
      "Average Trade Return: 2.19%\n",
      "Win Rate: 97.53%\n",
      "Sharpe Ratio: 19.25\n",
      "Number of Trades: 283\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.indicators import calculate_rsi, calculate_bollinger_bands\n",
    "\n",
    "\n",
    "def calculate_performance(trades):\n",
    "    if not trades:\n",
    "        return 0, 0, 0, 0\n",
    "    total_return = sum(trades)\n",
    "    avg_return = total_return / len(trades)\n",
    "    win_rate = sum(1 for t in trades if t > 0) / len(trades)\n",
    "    returns = np.array(trades)\n",
    "    sharpe_ratio = (returns.mean() / returns.std()) * np.sqrt(252)  # Annualized\n",
    "    return total_return, avg_return, win_rate, sharpe_ratio\n",
    "\n",
    "\n",
    "def prepare_data(df):\n",
    "    # Reset index to ensure it's unique\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Convert relevant columns to numeric types\n",
    "    numeric_columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    for col in numeric_columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Remove existing RSI column if it exists\n",
    "    if \"rsi\" in df.columns:\n",
    "        df = df.drop(\"rsi\", axis=1)\n",
    "\n",
    "    # Drop any rows with NaN values after conversion\n",
    "    df = df.dropna(subset=numeric_columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def backtest_rsi_bollinger_strategy(\n",
    "    df, rsi_period=14, bb_period=20, bb_std=2, rsi_oversold=35, rsi_overbought=70\n",
    "):\n",
    "    # Prepare the data\n",
    "    df = prepare_data(df)\n",
    "\n",
    "    # Calculate indicators\n",
    "    df[\"rsi\"] = calculate_rsi(df[\"close\"].values, period=rsi_period)\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    bb_upper, bb_middle, bb_lower = calculate_bollinger_bands(\n",
    "        df[\"close\"].values, period=bb_period, num_std_dev=bb_std\n",
    "    )\n",
    "\n",
    "    # Add Bollinger Bands to the DataFrame, aligning with the index\n",
    "    df[\"bb_upper\"] = pd.Series(bb_upper, index=df.index[: len(bb_upper)])\n",
    "    df[\"bb_middle\"] = pd.Series(bb_middle, index=df.index[: len(bb_middle)])\n",
    "    df[\"bb_lower\"] = pd.Series(bb_lower, index=df.index[: len(bb_lower)])\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Initialize variables\n",
    "    position = None\n",
    "    entry_price = 0\n",
    "    trades = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if i < max(rsi_period, bb_period):\n",
    "            continue  # Skip until we have enough data for indicators\n",
    "\n",
    "        row = df.iloc[i]\n",
    "        if position is None:\n",
    "            if row[\"rsi\"] < rsi_oversold and row[\"close\"] < row[\"bb_lower\"]:\n",
    "                position = \"long\"\n",
    "                entry_price = row[\"close\"]\n",
    "        elif position == \"long\":\n",
    "            if row[\"rsi\"] > rsi_overbought or row[\"close\"] > row[\"bb_upper\"]:\n",
    "                profit = (row[\"close\"] - entry_price) / entry_price\n",
    "                trades.append(profit)\n",
    "                position = None\n",
    "\n",
    "    return trades\n",
    "\n",
    "\n",
    "# Use the function\n",
    "trades = backtest_rsi_bollinger_strategy(historical_data)\n",
    "\n",
    "# Calculate performance metrics\n",
    "total_return, avg_return, win_rate, sharpe_ratio = calculate_performance(trades)\n",
    "\n",
    "print(historical_data.describe())\n",
    "\n",
    "# トレード詳細の表示\n",
    "print(\"\\nFirst 10 trades:\")\n",
    "print(trades[:10])\n",
    "print(\"\\nLast 10 trades:\")\n",
    "print(trades[-10:])\n",
    "\n",
    "print(f\"\\nBacktesting Results:\")\n",
    "print(f\"Total Return: {total_return:.2%}\")\n",
    "print(f\"Average Trade Return: {avg_return:.2%}\")\n",
    "print(f\"Win Rate: {win_rate:.2%}\")\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "print(f\"Number of Trades: {len(trades)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51840 entries, 0 to 287\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype                     \n",
      "---  ------     --------------  -----                     \n",
      " 0   timestamp  51840 non-null  datetime64[ns, Asia/Tokyo]\n",
      " 1   open       51840 non-null  object                    \n",
      " 2   high       51840 non-null  object                    \n",
      " 3   low        51840 non-null  object                    \n",
      " 4   close      51840 non-null  float64                   \n",
      " 5   volume     51840 non-null  object                    \n",
      " 6   rsi        51840 non-null  float64                   \n",
      "dtypes: datetime64[ns, Asia/Tokyo](1), float64(2), object(4)\n",
      "memory usage: 3.2+ MB\n",
      "None\n",
      "                  timestamp            open            high             low  \\\n",
      "0 2024-02-12 23:45:00+09:00  48556.30000000  48719.17000000  48455.51000000   \n",
      "1 2024-02-12 23:50:00+09:00  48606.20000000  48663.20000000  48520.00000000   \n",
      "2 2024-02-12 23:55:00+09:00  48623.66000000  48798.00000000  48595.00000000   \n",
      "3 2024-02-13 00:00:00+09:00  48797.99000000  48867.00000000  48669.39000000   \n",
      "4 2024-02-13 00:05:00+09:00  48866.80000000  48980.00000000  48738.85000000   \n",
      "\n",
      "      close         volume        rsi  \n",
      "0  48606.20   716.71369000  78.303395  \n",
      "1  48623.66   456.61425000  78.303395  \n",
      "2  48798.00   711.98091000  78.303395  \n",
      "3  48866.80   709.38659000  78.303395  \n",
      "4  48972.00  1127.47518000  78.303395  \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(historical_data.info())\n",
    "print(historical_data.head())\n",
    "print(historical_data.index.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# from src.utils.encryption import decrypt_file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class ConfigLoader:\n",
    "    def __init__(self):\n",
    "        self.config = None\n",
    "        self.secrets = None\n",
    "        self.config_mtime = 0\n",
    "        self.secrets_mtime = 0\n",
    "\n",
    "    def load_config(self):\n",
    "        current_mtime = os.path.getmtime(\"config/config.yaml\")\n",
    "        if current_mtime > self.config_mtime:\n",
    "            with open(\"config/config.yaml\", \"r\") as file:\n",
    "                self.config = yaml.safe_load(file)\n",
    "            self.config_mtime = current_mtime\n",
    "        return self.config\n",
    "\n",
    "    def load_secrets(self):\n",
    "        secrets_path = os.path.join(\"config\", \"secrets.yaml\")\n",
    "        with open(secrets_path, \"r\") as file:\n",
    "            self.secrets = yaml.safe_load(file)\n",
    "        return self.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trading': {'pair': 'BTCUSDT', 'amount': 0.001, 'interval_seconds': 300, 'rsi_period': 14, 'bollinger_period': 20, 'bollinger_std_dev': 2}}\n",
      "{'bybit': {'api_key': 'Jg22qo1LSji45UIsjA', 'api_secret': '27OvNMgl3twzyRbcytP9lw4vpWiOWULQ1Z5p'}}\n"
     ]
    }
   ],
   "source": [
    "config_loader = ConfigLoader()\n",
    "config = config_loader.load_config()\n",
    "secrets = config_loader.load_secrets()\n",
    "print(config)\n",
    "print(secrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current price of BTCUSDT is: 58597.24000000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_real_time_price(symbol):\n",
    "    url = f\"https://api.binance.com/api/v3/ticker/price\"\n",
    "    params = {\"symbol\": symbol}\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    return data[\"price\"]\n",
    "\n",
    "\n",
    "# 使用例\n",
    "symbol = \"BTCUSDT\"\n",
    "price = get_real_time_price(symbol)\n",
    "print(f\"The current price of {symbol} is: {price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s'\n",
      "The current price of BTCUSDT is: 58563.86000000\n",
      "The current price of BTCUSDT is: 58563.86000000\n",
      "The current price of BTCUSDT is: 58563.85000000\n",
      "The current price of BTCUSDT is: 58563.86000000\n",
      "The current price of BTCUSDT is: 58556.00000000\n",
      "The current price of BTCUSDT is: 58556.00000000\n",
      "The current price of BTCUSDT is: 58547.59000000\n",
      "The current price of BTCUSDT is: 58544.98000000\n",
      "\n",
      "on_close() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "import websocket\n",
    "import json\n",
    "\n",
    "\n",
    "def on_message(ws, message):\n",
    "    data = json.loads(message)\n",
    "    print(f\"The current price of {data['s']} is: {data['c']}\")\n",
    "\n",
    "\n",
    "def on_error(ws, error):\n",
    "    print(error)\n",
    "\n",
    "\n",
    "def on_close(ws):\n",
    "    print(\"### closed ###\")\n",
    "\n",
    "\n",
    "def on_open(ws):\n",
    "    # Subscribe to the ticker for a specific symbol\n",
    "    ws.send(json.dumps({\"method\": \"SUBSCRIBE\", \"params\": [\"btcusdt@ticker\"], \"id\": 1}))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    websocket_url = \"wss://stream.binance.com:9443/ws\"\n",
    "    ws = websocket.WebSocketApp(\n",
    "        websocket_url,\n",
    "        on_open=on_open,\n",
    "        on_message=on_message,\n",
    "        on_error=on_error,\n",
    "        on_close=on_close,\n",
    "    )\n",
    "    ws.run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many requests. Waiting before retrying...\n",
      "Too many requests. Waiting before retrying...\n",
      "Too many requests. Waiting before retrying...\n",
      "Too many requests. Waiting before retrying...\n",
      "Too many requests. Waiting before retrying...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Max retries exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 使用例\u001b[39;00m\n\u001b[1;32m     33\u001b[0m symbol \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBTCUSDT\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m price \u001b[38;5;241m=\u001b[39m \u001b[43mget_real_time_price_bybit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current price of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on Bybit is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[68], line 29\u001b[0m, in \u001b[0;36mget_real_time_price_bybit\u001b[0;34m(symbol)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError fetching data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         )\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax retries exceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Max retries exceeded"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def get_real_time_price_bybit(symbol):\n",
    "    url = f\"https://api.bybit.com/v2/public/tickers\"\n",
    "    params = {\"symbol\": symbol}\n",
    "\n",
    "    for attempt in range(5):  # 最大5回リトライ\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        # ステータスコードを確認\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()\n",
    "                if data[\"result\"]:\n",
    "                    return data[\"result\"][0][\"last_price\"]\n",
    "                else:\n",
    "                    raise Exception(\"No result found in response\")\n",
    "            except ValueError:\n",
    "                raise Exception(f\"Error decoding JSON response: {response.text}\")\n",
    "        elif response.status_code == 429:\n",
    "            print(\"Too many requests. Waiting before retrying...\")\n",
    "            time.sleep(5)  # 5秒待機\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Error fetching data: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "\n",
    "    raise Exception(\"Max retries exceeded\")\n",
    "\n",
    "\n",
    "# 使用例\n",
    "symbol = \"BTCUSDT\"\n",
    "price = get_real_time_price_bybit(symbol)\n",
    "print(f\"The current price of {symbol} on Bybit is: {price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    klines = await api.get_klines(\"BTCUSDT\", \"5\", 100)\n",
    "    latest_kline = klines[\"result\"][\"list\"][-1]\n",
    "    latest_timestamp = latest_kline[0]\n",
    "    latest_open = latest_kline[1]\n",
    "    latest_high = latest_kline[2]\n",
    "    latest_low = latest_kline[3]\n",
    "    latest_close = latest_kline[4]\n",
    "    latest_volume = latest_kline[5]\n",
    "    print(\"Latest Kline Data:\")\n",
    "    print(f\"Timestamp: {latest_timestamp}\")\n",
    "    print(f\"Open Price: {latest_open}\")\n",
    "    print(f\"High Price: {latest_high}\")\n",
    "    print(f\"Low Price: {latest_low}\")\n",
    "    print(f\"Close Price: {latest_close}\")\n",
    "    print(f\"Volume: {latest_volume}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bybit_tradingbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
